{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "-------------------------------------------------\n",
    "   File Name：     baidu_crawler\n",
    "   Description :\n",
    "   Author :       dik\n",
    "   date：          2018/11/27\n",
    "-------------------------------------------------\n",
    "   Change Activity:\n",
    "                   2018/11/27:\n",
    "-------------------------------------------------\n",
    "\"\"\"\n",
    "__author__ = 'dik'\n",
    "\n",
    "# coding = utf-8\n",
    "import urllib.request\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def getDatas(keyword, pages):\n",
    "    params = []\n",
    "    for i in range(30, 30 * pages + 30, 30):\n",
    "        params.append({\n",
    "            'tn': 'resultjson_com',\n",
    "            'ipn': 'rj',\n",
    "            'ct': 201326592,\n",
    "            'is': '',\n",
    "            'fp': 'result',\n",
    "            'queryWord': keyword,\n",
    "            'cl': 2,\n",
    "            'lm': -1,\n",
    "            'ie': 'utf-8',\n",
    "            'oe': 'utf-8',\n",
    "            'adpicid': '',\n",
    "            'st': -1,\n",
    "            'z': '',\n",
    "            'ic': 0,\n",
    "            'word': keyword,\n",
    "            's': '',\n",
    "            'se': '',\n",
    "            'tab': '',\n",
    "            'width': '',\n",
    "            'height': '',\n",
    "            'face': 0,\n",
    "            'istype': 2,\n",
    "            'qc': '',\n",
    "            'nc': 1,\n",
    "            'fr': '',\n",
    "            'pn': i,\n",
    "            'rn': 30,\n",
    "            'gsm': '1e',\n",
    "            '1526377465547': ''\n",
    "        })\n",
    "        \n",
    "    url = 'https://image.baidu.com/search/index'\n",
    "    urls = []\n",
    "    for i in params:\n",
    "        urls.append(requests.get(url, params=i).json().get('data'))\n",
    "\n",
    "    return urls\n",
    "\n",
    "\n",
    "def getImg(datalist, path):\n",
    "    x = 0\n",
    "    for list in datalist:\n",
    "        for i in list:\n",
    "            if i.get('thumbURL') != None:\n",
    "                print('正在下载：%s' % i.get('thumbURL'))\n",
    "                #如果报错停止10秒后再继续\n",
    "                try:\n",
    "                    urllib.request.urlretrieve(i.get('thumbURL'), path + '%d.jpg' % x)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    time.sleep(10)\n",
    "                x += 1\n",
    "            else:\n",
    "                print('图片链接不存在')\n",
    "                \n",
    "            time.sleep(2)#间隔1s，防止被封IP\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    datalist = getDatas('狮子鱼', 100)#关键词，要爬的页数\n",
    "    getImg(datalist, r'F:\\anacondapython\\shiziyu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "-------------------------------------------------\n",
    "   File Name：     baidu_crawler\n",
    "   Description :\n",
    "   Author :       dik\n",
    "   date：          2018/11/27\n",
    "-------------------------------------------------\n",
    "   Change Activity:\n",
    "                   2018/11/27:\n",
    "-------------------------------------------------\n",
    "\"\"\"\n",
    "__author__ = 'dik'\n",
    "\n",
    "# coding = utf-8\n",
    "import urllib.request\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def getDatas(keyword, pages):\n",
    "    params = []\n",
    "    for i in range(30, 30 * pages + 30, 30):\n",
    "        params.append({\n",
    "            'tn': 'resultjson_com',\n",
    "            'ipn': 'rj',\n",
    "            'ct': 201326592,\n",
    "            'is': '',\n",
    "            'fp': 'result',\n",
    "            'queryWord': keyword,\n",
    "            'cl': 2,\n",
    "            'lm': -1,\n",
    "            'ie': 'utf-8',\n",
    "            'oe': 'utf-8',\n",
    "            'adpicid': '',\n",
    "            'st': -1,\n",
    "            'z': '',\n",
    "            'ic': 0,\n",
    "            'word': keyword,\n",
    "            's': '',\n",
    "            'se': '',\n",
    "            'tab': '',\n",
    "            'width': '',\n",
    "            'height': '',\n",
    "            'face': 0,\n",
    "            'istype': 2,\n",
    "            'qc': '',\n",
    "            'nc': 1,\n",
    "            'fr': '',\n",
    "            'pn': i,\n",
    "            'rn': 30,\n",
    "            'gsm': '1e',\n",
    "            '1526377465547': ''\n",
    "        })\n",
    "\n",
    "    url = 'https://image.baidu.com/search/index'\n",
    "    urls = []\n",
    "    for i in params:\n",
    "        urls.append(requests.get(url, params=i).json().get('data'))\n",
    "\n",
    "    return urls\n",
    "\n",
    "\n",
    "def getImg(datalist, path):\n",
    "    x = 0\n",
    "    for list in datalist:\n",
    "        for i in list:\n",
    "            if i.get('thumbURL') != None:\n",
    "                print('正在下载：%s' % i.get('thumbURL'))\n",
    "                #如果报错停止10秒后再继续\n",
    "                try:\n",
    "                    urllib.request.urlretrieve(i.get('thumbURL'), path + '%d.jpg' % x)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    time.sleep(10)\n",
    "                x += 1\n",
    "            else:\n",
    "                print('图片链接不存在')\n",
    "\n",
    "            time.sleep(2)  # 间隔2s，防止被封IP\n",
    "if __name__ == '__main__':\n",
    "    datalist = getDatas('臭肚鱼', 100)#关键词，要爬的页数\n",
    "    getImg(datalist,r'F:\\anacondapython\\chouduyu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "-------------------------------------------------\n",
    "   File Name：     baidu_crawler\n",
    "   Description :   最终版本\n",
    "   Author :       dik\n",
    "   date：          2018/11/27\n",
    "-------------------------------------------------\n",
    "   Change Activity:\n",
    "                   2018/11/27:\n",
    "-------------------------------------------------\n",
    "\"\"\"\n",
    "__author__ = 'dik'\n",
    "\n",
    "# coding = utf-8\n",
    "import urllib.request\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "\n",
    "def getDatas(keyword, pages):\n",
    "    params = []\n",
    "    for i in range(30, 30 * pages + 30, 30):\n",
    "        params.append({\n",
    "            'tn': 'resultjson_com',\n",
    "            'ipn': 'rj',\n",
    "            'ct': 201326592,\n",
    "            'is': '',\n",
    "            'fp': 'result',\n",
    "            'queryWord': keyword,\n",
    "            'cl': 2,\n",
    "            'lm': -1,\n",
    "            'ie': 'utf-8',\n",
    "            'oe': 'utf-8',\n",
    "            'adpicid': '',\n",
    "            'st': -1,\n",
    "            'z': '',\n",
    "            'ic': 0,\n",
    "            'word': keyword,\n",
    "            's': '',\n",
    "            'se': '',\n",
    "            'tab': '',\n",
    "            'width': '',\n",
    "            'height': '',\n",
    "            'face': 0,\n",
    "            'istype': 2,\n",
    "            'qc': '',\n",
    "            'nc': 1,\n",
    "            'fr': '',\n",
    "            'pn': i,\n",
    "            'rn': 30,\n",
    "            'gsm': '1e',\n",
    "            '1526377465547': ''\n",
    "        })\n",
    "\n",
    "    url = 'https://image.baidu.com/search/index'\n",
    "    urls = []\n",
    "    for i in params:\n",
    "        try:\n",
    "            urls.append(requests.get(url, params=i).json().get('data'))\n",
    "#             print(urls)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    return urls\n",
    "\n",
    "\n",
    "def getImg(datalist, path):\n",
    "    x = 0\n",
    "    for list in datalist:\n",
    "        for i in list:\n",
    "            if i.get('thumbURL') != None:\n",
    "                print('正在下载：%s' % i.get('thumbURL'))\n",
    "                #如果报错停止10秒后再继续\n",
    "                try:\n",
    "                    urllib.request.urlretrieve(i.get('thumbURL'), path + '%d.jpg' % x)\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "                    time.sleep(10)\n",
    "                x += 1\n",
    "            else:\n",
    "                print('图片链接不存在')\n",
    "\n",
    "            time.sleep(2)  # 间隔2s，防止被封IP\n",
    "if __name__ == '__main__':\n",
    "    datalist = getDatas('臭肚鱼', 100)#关键词，要爬的页数\n",
    "    getImg(datalist, r'F:\\anacondapython\\chouduyu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
